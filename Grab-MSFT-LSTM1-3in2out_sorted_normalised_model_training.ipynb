{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grab-Microsoft Challenge \n",
    "## Traffic Management\n",
    "\n",
    "- geohash6: geohash is a public domain geocoding system which encodes a geographic location into a short string of letters and digits with arbitrary precision. You are free to use any geohash library to encode/decode the geohashes into latitude and longitude or vice versa.(Examples:https://github.com/hkwi/python-geohash)\n",
    "- day: the value indicates the sequential order and not a particular day of the month\n",
    "- timestamp: start time of 15-minute intervals in the following format: <hour>:<minute>, where hour ranges from 0 to 23 and minute is either one of (0, 15, 30, 45)\n",
    "- demand: aggregated demand normalised to be in the range [0,1]\n",
    "    \n",
    "## Problem Statements:\n",
    "- Which areas have high / low traffic demand?\n",
    "- How does regional traffic demand change according to day / time?\n",
    "- Forecast the travel demand for next 15min / 1hour and predict areas with high travel demand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is train LSTM model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import python library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import array\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plot matplotlib graph\n",
    "%matplotlib inline\n",
    "\n",
    "#Import models from scikit learn module:\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Flatten, LSTM, BatchNormalization\n",
    "from tensorflow.keras import regularizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import h5py\n",
    "import sklearn.metrics as metrics\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,CSVLogger\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.utils import plot_model \n",
    "\n",
    "import pickle\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "modelname   = 'LSTM1-3in2out_sorted_normalised'\n",
    "batch_size  = 1024\n",
    "no_of_epoch = 20\n",
    "no_of_train = 0.8\n",
    "\n",
    "# choose a number of time steps\n",
    "n_steps_in, predict_next_no_of_output = 3, 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createModel(): \n",
    "    inputs  = Input(shape=(X_train.shape[1],X_train.shape[2]))\n",
    "    y = LSTM(units=64, return_sequences=True, dropout=0.5, recurrent_dropout=0.2)(inputs)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = LSTM(1024, return_sequences=True, dropout=0.5, recurrent_dropout=0.2)(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = LSTM(1024, return_sequences=True, dropout=0.5, recurrent_dropout=0.3)(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = LSTM(512, return_sequences=True, dropout=0.5, recurrent_dropout=0.4)(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = LSTM(512, return_sequences=True, dropout=0.5,recurrent_dropout=0.5)(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = LSTM(128, dropout=0.5,recurrent_dropout=0.5)(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Dense(predict_next_no_of_output, activation='sigmoid')(y)\n",
    "  \n",
    "    model = Model(inputs=inputs,outputs=y)\n",
    "    model.compile(loss='mse',optimizer='adam', metrics=['mse', 'mae'])\n",
    "    return model\n",
    "\n",
    "# split a multivariate sequence into samples\n",
    "def split_sequences(sequences, n_steps_in, n_steps_out):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequences)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps_in\n",
    "        out_end_ix = end_ix + n_steps_out-1\n",
    "        # check if we are beyond the dataset\n",
    "        if out_end_ix > len(sequences):\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequences[i:end_ix, :-1], sequences[end_ix-1:out_end_ix, -1]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return array(X), array(y)\n",
    "\n",
    "# normalisation of data\n",
    "def norm(x):\n",
    "    data = pd.read_excel('data/normalisation_mean_std.xlsx', sheet_name='Normalised', index_col=0)\n",
    "    mean = data['mean']\n",
    "    std  = data['std']\n",
    "    \n",
    "    return (x - mean) / std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading from Preprocessed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>min</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>demand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.723421</td>\n",
       "      <td>-1.500805</td>\n",
       "      <td>-1.338235</td>\n",
       "      <td>0.481907</td>\n",
       "      <td>1.383892</td>\n",
       "      <td>0.021212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.723421</td>\n",
       "      <td>-1.500805</td>\n",
       "      <td>-1.338235</td>\n",
       "      <td>1.644371</td>\n",
       "      <td>1.490828</td>\n",
       "      <td>0.013217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.723421</td>\n",
       "      <td>-1.500805</td>\n",
       "      <td>-1.338235</td>\n",
       "      <td>0.094420</td>\n",
       "      <td>-0.968706</td>\n",
       "      <td>0.157956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.723421</td>\n",
       "      <td>-1.500805</td>\n",
       "      <td>-1.338235</td>\n",
       "      <td>1.160011</td>\n",
       "      <td>-0.327088</td>\n",
       "      <td>0.001262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.723421</td>\n",
       "      <td>-1.500805</td>\n",
       "      <td>-1.338235</td>\n",
       "      <td>0.385035</td>\n",
       "      <td>-1.396451</td>\n",
       "      <td>0.032721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048570</th>\n",
       "      <td>1.670463</td>\n",
       "      <td>2.015857</td>\n",
       "      <td>1.343362</td>\n",
       "      <td>-0.099324</td>\n",
       "      <td>-0.968706</td>\n",
       "      <td>0.041818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048571</th>\n",
       "      <td>1.670463</td>\n",
       "      <td>2.015857</td>\n",
       "      <td>1.343362</td>\n",
       "      <td>-0.293068</td>\n",
       "      <td>0.100657</td>\n",
       "      <td>0.061371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048572</th>\n",
       "      <td>1.670463</td>\n",
       "      <td>2.015857</td>\n",
       "      <td>1.343362</td>\n",
       "      <td>0.385035</td>\n",
       "      <td>0.100657</td>\n",
       "      <td>0.005397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048573</th>\n",
       "      <td>1.670463</td>\n",
       "      <td>2.015857</td>\n",
       "      <td>1.343362</td>\n",
       "      <td>-1.455532</td>\n",
       "      <td>0.314530</td>\n",
       "      <td>0.001453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048574</th>\n",
       "      <td>1.670463</td>\n",
       "      <td>2.015857</td>\n",
       "      <td>1.343362</td>\n",
       "      <td>-0.486812</td>\n",
       "      <td>1.063083</td>\n",
       "      <td>0.141996</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1048575 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              day      hour       min       lat      long    demand\n",
       "0       -1.723421 -1.500805 -1.338235  0.481907  1.383892  0.021212\n",
       "1       -1.723421 -1.500805 -1.338235  1.644371  1.490828  0.013217\n",
       "2       -1.723421 -1.500805 -1.338235  0.094420 -0.968706  0.157956\n",
       "3       -1.723421 -1.500805 -1.338235  1.160011 -0.327088  0.001262\n",
       "4       -1.723421 -1.500805 -1.338235  0.385035 -1.396451  0.032721\n",
       "...           ...       ...       ...       ...       ...       ...\n",
       "1048570  1.670463  2.015857  1.343362 -0.099324 -0.968706  0.041818\n",
       "1048571  1.670463  2.015857  1.343362 -0.293068  0.100657  0.061371\n",
       "1048572  1.670463  2.015857  1.343362  0.385035  0.100657  0.005397\n",
       "1048573  1.670463  2.015857  1.343362 -1.455532  0.314530  0.001453\n",
       "1048574  1.670463  2.015857  1.343362 -0.486812  1.063083  0.141996\n",
       "\n",
       "[1048575 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xls  = pd.ExcelFile('data/Dataset_feature_sorted_normalised.xlsx')\n",
    "data = pd.read_excel(xls, 'TrafficMgmt')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_var = ['day', 'hour', 'min', 'lat', 'long']\n",
    "outcome_var   = 'demand'\n",
    "no_of_features = len(predictor_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>min</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>demand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.723421</td>\n",
       "      <td>-1.500805</td>\n",
       "      <td>-1.338235</td>\n",
       "      <td>0.481907</td>\n",
       "      <td>1.383892</td>\n",
       "      <td>0.021212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.723421</td>\n",
       "      <td>-1.500805</td>\n",
       "      <td>-1.338235</td>\n",
       "      <td>1.644371</td>\n",
       "      <td>1.490828</td>\n",
       "      <td>0.013217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.723421</td>\n",
       "      <td>-1.500805</td>\n",
       "      <td>-1.338235</td>\n",
       "      <td>0.094420</td>\n",
       "      <td>-0.968706</td>\n",
       "      <td>0.157956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.723421</td>\n",
       "      <td>-1.500805</td>\n",
       "      <td>-1.338235</td>\n",
       "      <td>1.160011</td>\n",
       "      <td>-0.327088</td>\n",
       "      <td>0.001262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.723421</td>\n",
       "      <td>-1.500805</td>\n",
       "      <td>-1.338235</td>\n",
       "      <td>0.385035</td>\n",
       "      <td>-1.396451</td>\n",
       "      <td>0.032721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048570</th>\n",
       "      <td>1.670463</td>\n",
       "      <td>2.015857</td>\n",
       "      <td>1.343362</td>\n",
       "      <td>-0.099324</td>\n",
       "      <td>-0.968706</td>\n",
       "      <td>0.041818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048571</th>\n",
       "      <td>1.670463</td>\n",
       "      <td>2.015857</td>\n",
       "      <td>1.343362</td>\n",
       "      <td>-0.293068</td>\n",
       "      <td>0.100657</td>\n",
       "      <td>0.061371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048572</th>\n",
       "      <td>1.670463</td>\n",
       "      <td>2.015857</td>\n",
       "      <td>1.343362</td>\n",
       "      <td>0.385035</td>\n",
       "      <td>0.100657</td>\n",
       "      <td>0.005397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048573</th>\n",
       "      <td>1.670463</td>\n",
       "      <td>2.015857</td>\n",
       "      <td>1.343362</td>\n",
       "      <td>-1.455532</td>\n",
       "      <td>0.314530</td>\n",
       "      <td>0.001453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048574</th>\n",
       "      <td>1.670463</td>\n",
       "      <td>2.015857</td>\n",
       "      <td>1.343362</td>\n",
       "      <td>-0.486812</td>\n",
       "      <td>1.063083</td>\n",
       "      <td>0.141996</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1048575 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              day      hour       min       lat      long    demand\n",
       "0       -1.723421 -1.500805 -1.338235  0.481907  1.383892  0.021212\n",
       "1       -1.723421 -1.500805 -1.338235  1.644371  1.490828  0.013217\n",
       "2       -1.723421 -1.500805 -1.338235  0.094420 -0.968706  0.157956\n",
       "3       -1.723421 -1.500805 -1.338235  1.160011 -0.327088  0.001262\n",
       "4       -1.723421 -1.500805 -1.338235  0.385035 -1.396451  0.032721\n",
       "...           ...       ...       ...       ...       ...       ...\n",
       "1048570  1.670463  2.015857  1.343362 -0.099324 -0.968706  0.041818\n",
       "1048571  1.670463  2.015857  1.343362 -0.293068  0.100657  0.061371\n",
       "1048572  1.670463  2.015857  1.343362  0.385035  0.100657  0.005397\n",
       "1048573  1.670463  2.015857  1.343362 -1.455532  0.314530  0.001453\n",
       "1048574  1.670463  2.015857  1.343362 -0.486812  1.063083  0.141996\n",
       "\n",
       "[1048575 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[['day', 'hour', 'min', 'lat', 'long','demand']]\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare training & test data\n",
    "- Since this is a time series dataset, we can try using LSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.72342100e+00, -1.50080507e+00, -1.33823457e+00,\n",
       "         4.81907401e-01,  1.38389211e+00,  2.12124070e-02],\n",
       "       [-1.72342100e+00, -1.50080507e+00, -1.33823457e+00,\n",
       "         1.64437101e+00,  1.49082837e+00,  1.32167260e-02],\n",
       "       [-1.72342100e+00, -1.50080507e+00, -1.33823457e+00,\n",
       "         9.44195313e-02, -9.68705602e-01,  1.57956413e-01],\n",
       "       ...,\n",
       "       [ 1.67046336e+00,  2.01585687e+00,  1.34336210e+00,\n",
       "         3.85035434e-01,  1.00656996e-01,  5.39676900e-03],\n",
       "       [ 1.67046336e+00,  2.01585687e+00,  1.34336210e+00,\n",
       "        -1.45553195e+00,  3.14529515e-01,  1.45313800e-03],\n",
       "       [ 1.67046336e+00,  2.01585687e+00,  1.34336210e+00,\n",
       "        -4.86812273e-01,  1.06308333e+00,  1.41995720e-01]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = data.to_numpy()\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1048572, 3, 5) (1048572, 2)\n"
     ]
    }
   ],
   "source": [
    "# covert into input/output\n",
    "X, y = split_sequences(dataset, n_steps_in, predict_next_no_of_output)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.723421   -1.50080507 -1.33823457  0.4819074   1.38389211]\n",
      " [-1.723421   -1.50080507 -1.33823457  1.64437101  1.49082837]\n",
      " [-1.723421   -1.50080507 -1.33823457  0.09441953 -0.9687056 ]] [0.15795641 0.00126166]\n",
      "[[-1.723421   -1.50080507 -1.33823457  1.64437101  1.49082837]\n",
      " [-1.723421   -1.50080507 -1.33823457  0.09441953 -0.9687056 ]\n",
      " [-1.723421   -1.50080507 -1.33823457  1.16001117 -0.32708804]] [0.00126166 0.03272106]\n",
      "[[-1.723421   -1.50080507 -1.33823457  0.09441953 -0.9687056 ]\n",
      " [-1.723421   -1.50080507 -1.33823457  1.16001117 -0.32708804]\n",
      " [-1.723421   -1.50080507 -1.33823457  0.38503543 -1.39645064]] [0.03272106 0.03925688]\n"
     ]
    }
   ],
   "source": [
    "# summarize the data\n",
    "for i in range(3):\n",
    "    print(X[i], y[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train-test-val dataset split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1 = X[:int(no_of_train*len(X))]\n",
    "y_train1 = y[:int(no_of_train*len(X))]\n",
    "X_test  = X[int(no_of_train*len(X)):]\n",
    "y_test  = y[int(no_of_train*len(X)):]\n",
    "\n",
    "X_train = X_train1[:int(no_of_train*len(X_train1))]\n",
    "y_train = y_train1[:int(no_of_train*len(X_train1))]\n",
    "X_val   = X_train1[int(no_of_train*len(X_train1)):]\n",
    "y_val   = y_train1[int(no_of_train*len(X_train1)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(671085, 3, 5) (671085, 2) (209715, 3, 5) (209715, 2) (167772, 3, 5) (167772, 2)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape,X_test.shape, y_test.shape,X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><center>Create Model and test</center><h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>LSTM<h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 3, 5)]            0         \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 3, 64)             17920     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 3, 64)             256       \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 3, 1024)           4460544   \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 3, 1024)           4096      \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 3, 1024)           8392704   \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 3, 1024)           4096      \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 3, 512)            3147776   \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 3, 512)            2048      \n",
      "_________________________________________________________________\n",
      "lstm_10 (LSTM)               (None, 3, 512)            2099200   \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 3, 512)            2048      \n",
      "_________________________________________________________________\n",
      "lstm_11 (LSTM)               (None, 128)               328192    \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 18,459,650\n",
      "Trainable params: 18,453,122\n",
      "Non-trainable params: 6,528\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = createModel()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse',optimizer='adam', metrics=['mse', 'mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create checkpoints to save model during training and save training data into csv\n",
    "# â€˜monitorâ€™ can be â€˜val_accâ€™ or â€˜val_lossâ€™\n",
    "# When set to â€˜val_accâ€™, â€˜modeâ€™ must be â€˜maxâ€™; when set to â€˜val_lossâ€™, â€˜modeâ€™ must be â€˜minâ€™\n",
    "\n",
    "filepath       = modelname + \".hdf5\"\n",
    "checkpoint     = ModelCheckpoint(filepath, monitor='val_loss',verbose=0,save_best_only=True,mode='min') \n",
    "csv_logger     = CSVLogger(modelname + '.csv')\n",
    "callbacks_list = [checkpoint,csv_logger]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 671085 samples, validate on 167772 samples\n",
      "Epoch 1/20\n",
      "671085/671085 [==============================] - 90s 134us/sample - loss: 0.0414 - mse: 0.0414 - mae: 0.1307 - val_loss: 0.0249 - val_mse: 0.0249 - val_mae: 0.1033\n",
      "Epoch 2/20\n",
      "671085/671085 [==============================] - 89s 133us/sample - loss: 0.0244 - mse: 0.0244 - mae: 0.0951 - val_loss: 0.0249 - val_mse: 0.0249 - val_mae: 0.1015\n",
      "Epoch 3/20\n",
      "671085/671085 [==============================] - 89s 133us/sample - loss: 0.0244 - mse: 0.0244 - mae: 0.0951 - val_loss: 0.0249 - val_mse: 0.0249 - val_mae: 0.1030\n",
      "Epoch 4/20\n",
      "671085/671085 [==============================] - 91s 135us/sample - loss: 0.0244 - mse: 0.0244 - mae: 0.0951 - val_loss: 0.0250 - val_mse: 0.0250 - val_mae: 0.1041\n",
      "Epoch 5/20\n",
      "671085/671085 [==============================] - 91s 136us/sample - loss: 0.0244 - mse: 0.0244 - mae: 0.0951 - val_loss: 0.0251 - val_mse: 0.0251 - val_mae: 0.1041\n",
      "Epoch 6/20\n",
      "671085/671085 [==============================] - 91s 136us/sample - loss: 0.0244 - mse: 0.0244 - mae: 0.0951 - val_loss: 0.0250 - val_mse: 0.0250 - val_mae: 0.1029\n",
      "Epoch 7/20\n",
      "671085/671085 [==============================] - 91s 135us/sample - loss: 0.0244 - mse: 0.0244 - mae: 0.0950 - val_loss: 0.0249 - val_mse: 0.0249 - val_mae: 0.1026\n",
      "Epoch 8/20\n",
      "671085/671085 [==============================] - 90s 134us/sample - loss: 0.0244 - mse: 0.0244 - mae: 0.0951 - val_loss: 0.0249 - val_mse: 0.0249 - val_mae: 0.1023\n",
      "Epoch 9/20\n",
      "671085/671085 [==============================] - 92s 137us/sample - loss: 0.0244 - mse: 0.0244 - mae: 0.0950 - val_loss: 0.0249 - val_mse: 0.0249 - val_mae: 0.1025\n",
      "Epoch 10/20\n",
      "671085/671085 [==============================] - 96s 143us/sample - loss: 0.0244 - mse: 0.0244 - mae: 0.0951 - val_loss: 0.0249 - val_mse: 0.0249 - val_mae: 0.1014\n",
      "Epoch 11/20\n",
      "671085/671085 [==============================] - 90s 134us/sample - loss: 0.0244 - mse: 0.0244 - mae: 0.0950 - val_loss: 0.0250 - val_mse: 0.0250 - val_mae: 0.1021\n",
      "Epoch 12/20\n",
      "671085/671085 [==============================] - 86s 128us/sample - loss: 0.0244 - mse: 0.0244 - mae: 0.0950 - val_loss: 0.0249 - val_mse: 0.0249 - val_mae: 0.1028\n",
      "Epoch 13/20\n",
      "671085/671085 [==============================] - 87s 129us/sample - loss: 0.0244 - mse: 0.0244 - mae: 0.0951 - val_loss: 0.0251 - val_mse: 0.0251 - val_mae: 0.1041\n",
      "Epoch 14/20\n",
      "671085/671085 [==============================] - 87s 130us/sample - loss: 0.0244 - mse: 0.0244 - mae: 0.0950 - val_loss: 0.0249 - val_mse: 0.0249 - val_mae: 0.1033\n",
      "Epoch 15/20\n",
      "671085/671085 [==============================] - 87s 130us/sample - loss: 0.0244 - mse: 0.0244 - mae: 0.0951 - val_loss: 0.0249 - val_mse: 0.0249 - val_mae: 0.1035\n",
      "Epoch 16/20\n",
      "671085/671085 [==============================] - 87s 130us/sample - loss: 0.0244 - mse: 0.0244 - mae: 0.0951 - val_loss: 0.0248 - val_mse: 0.0248 - val_mae: 0.1014\n",
      "Epoch 17/20\n",
      "671085/671085 [==============================] - 87s 129us/sample - loss: 0.0244 - mse: 0.0244 - mae: 0.0951 - val_loss: 0.0250 - val_mse: 0.0250 - val_mae: 0.1039\n",
      "Epoch 18/20\n",
      "671085/671085 [==============================] - 88s 131us/sample - loss: 0.0244 - mse: 0.0244 - mae: 0.0951 - val_loss: 0.0250 - val_mse: 0.0250 - val_mae: 0.1029\n",
      "Epoch 19/20\n",
      "671085/671085 [==============================] - 88s 131us/sample - loss: 0.0244 - mse: 0.0244 - mae: 0.0951 - val_loss: 0.0248 - val_mse: 0.0248 - val_mae: 0.1017\n",
      "Epoch 20/20\n",
      "671085/671085 [==============================] - 87s 129us/sample - loss: 0.0244 - mse: 0.0244 - mae: 0.0951 - val_loss: 0.0249 - val_mse: 0.0249 - val_mae: 0.1025\n"
     ]
    }
   ],
   "source": [
    "# The line for training\n",
    "history = model.fit(X_train, \n",
    "                     y_train, \n",
    "                     validation_data=(X_val, y_val), \n",
    "                     epochs=no_of_epoch, \n",
    "                     batch_size=batch_size,\n",
    "                     shuffle=False,\n",
    "                     callbacks=callbacks_list) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test dataset test result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.028873923463451252\n"
     ]
    }
   ],
   "source": [
    "predicted_value = model.predict(X_test)\n",
    "print(mean_squared_error(y_test,predicted_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'val_mae'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\deep\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2645\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2646\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2647\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'val_mae'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-8d4e81597033>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_xticklabels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_mae'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"val_mae\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"val_loss\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"loss\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\deep\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2798\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2799\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2800\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2801\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2802\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\deep\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2646\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2647\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2648\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2649\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2650\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'val_mae'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "records     = pd.read_csv(modelname +'.csv')\n",
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "ax          = plt.gca()\n",
    "ax.set_xticklabels([])\n",
    "\n",
    "plt.plot(records['val_mae'],label=\"val_mae\")\n",
    "plt.plot(records['val_loss'],label=\"val_loss\")\n",
    "plt.plot(records['loss'],label=\"loss\")\n",
    "plt.title('MAE',fontsize=12)\n",
    "plt.legend(loc=\"upper left\",fontsize=15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load saved trained model and scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your own trained model & scaler\n",
    "model           = load_model(filepath, compile = False)\n",
    "scaler_filename = \"grab_msft_sorted_scaler.save\"\n",
    "scaler          = joblib.load(scaler_filename) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "xls  = pd.ExcelFile('data/test_sample_sorted_8000.xlsx')\n",
    "test_sample = pd.read_excel(xls, 'TrafficMgmt')\n",
    "\n",
    "# Apply normalisation to sample test data\n",
    "test_sample[['day','hour','min','lat','long']] = norm(test_sample[['day','hour','min','lat','long']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18, 3, 5) (18, 2)\n"
     ]
    }
   ],
   "source": [
    "# covert into input/output\n",
    "test_sample_array = test_sample.to_numpy()\n",
    "X_sample, y_sample = split_sequences(test_sample_array, n_steps_in, predict_next_no_of_output)\n",
    "print(X_sample.shape, y_sample.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted value : [[0.10917372 0.11170594]\n",
      " [0.12884027 0.12812077]\n",
      " [0.12884027 0.1281208 ]\n",
      " [0.12884022 0.12812074]\n",
      " [0.12882563 0.12809661]\n",
      " [0.12884027 0.12812078]\n",
      " [0.1288399  0.12812017]\n",
      " [0.12884018 0.12812065]\n",
      " [0.12884018 0.12812065]\n",
      " [0.12884021 0.12812074]\n",
      " [0.12884027 0.1281208 ]\n",
      " [0.12883875 0.12811829]\n",
      " [0.12884013 0.12812056]\n",
      " [0.1096923  0.10973983]\n",
      " [0.12884021 0.1281207 ]\n",
      " [0.11280828 0.11413889]\n",
      " [0.11671405 0.11852096]\n",
      " [0.12884001 0.12812042]] \n",
      " Actual Value    : [[0.01799946 0.0531276 ]\n",
      " [0.0531276  0.10812558]\n",
      " [0.10812558 0.03172353]\n",
      " [0.03172353 0.08252318]\n",
      " [0.08252318 0.64191406]\n",
      " [0.64191406 0.13738873]\n",
      " [0.13738873 0.20788158]\n",
      " [0.20788158 0.23219486]\n",
      " [0.23219486 0.00794347]\n",
      " [0.00794347 0.00706648]\n",
      " [0.00706648 0.28443333]\n",
      " [0.28443333 0.67788291]\n",
      " [0.67788291 0.15390443]\n",
      " [0.15390443 0.01326358]\n",
      " [0.01326358 0.06040241]\n",
      " [0.06040241 0.03081827]\n",
      " [0.03081827 0.04285664]\n",
      " [0.04285664 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "predicted_value = model.predict(X_sample)\n",
    "print('Predicted value : {} \\n Actual Value    : {}' .format(predicted_value,y_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05927476725770406\n"
     ]
    }
   ],
   "source": [
    "print(mean_squared_error(y_sample,predicted_value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing using 1 row of inference data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Data input sequence format :\n",
    "test_data1  = [[18,20, 0, -5.353088, 90.653687],\n",
    "               [10,14,30, -5.413513, 90.664673],\n",
    "               [ 9, 6,15, -5.325623, 90.906372]]\n",
    "test_data2  = [[32, 5, 0, -5.353088, 90.752563],\n",
    "               [15, 4, 0, -5.413513, 90.719604],\n",
    "               [ 1,12,15, -5.336609, 90.609741]]\n",
    "test_data3  = [[25, 3,30, -5.391541, 90.818481],\n",
    "               [51,20,45, -5.408020, 90.631714],\n",
    "               [48, 6,15, -5.364075, 90.763550]]\n",
    "test_data4  = [[ 4,22,15, -5.402527, 90.675659],\n",
    "               [45, 9,15, -5.402527, 90.917358],\n",
    "               [52,11,45, -5.364075, 90.664673]]\n",
    "test_data5  = [[46,12,15, -5.353088, 90.642700],\n",
    "               [34,14,45, -5.375061, 90.807495],\n",
    "               [40, 2,30, -5.424500, 90.785522]]\n",
    "test_data6  = [[14,14,45, -5.391541, 90.598755],\n",
    "               [27, 3,30, -5.320129, 90.785522],\n",
    "               [ 6,23,45, -5.358582, 90.752563]]\n",
    "\n",
    "test_target1 = [[0.102821],[0.088755]]\n",
    "test_target2 = [[0.023843],[0.007460]]\n",
    "test_target3 = [[0.054170],[0.123463]]\n",
    "test_target4 = [[0.359406],[0.514136]]\n",
    "test_target5 = [[0.026409],[0.013998]]\n",
    "test_target6 = [[0.029400],[0.057255]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First set of testdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted value : [[0.11125613 0.11028143]]\n",
      "Actual Value    : [[0.102821], [0.088755]]\n"
     ]
    }
   ],
   "source": [
    "Data_scaled = scaler.transform(test_data1)\n",
    "Data_scaled = Data_scaled.reshape(1,n_steps_in,no_of_features)\n",
    "predicted_value = model.predict(Data_scaled)\n",
    "print('Predicted value : {}\\nActual Value    : {}' .format(predicted_value,test_target1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted value : [[0.11109656 0.10981342]]\n",
      "Actual Value    : [[0.023843], [0.00746]]\n"
     ]
    }
   ],
   "source": [
    "Data_scaled = scaler.transform(test_data2)\n",
    "Data_scaled = Data_scaled.reshape(1,n_steps_in,no_of_features)\n",
    "predicted_value = model.predict(Data_scaled)\n",
    "print('Predicted value : {}\\nActual Value    : {}' .format(predicted_value,test_target2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted value : [[0.12883306 0.1281089 ]]\n",
      "Actual Value    : [[0.05417], [0.123463]]\n"
     ]
    }
   ],
   "source": [
    "Data_scaled = scaler.transform(test_data3)\n",
    "Data_scaled = Data_scaled.reshape(1,n_steps_in,no_of_features)\n",
    "predicted_value = model.predict(Data_scaled)\n",
    "print('Predicted value : {}\\nActual Value    : {}' .format(predicted_value,test_target3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted value : [[0.12878662 0.12803216]]\n",
      "Actual Value    : [[0.359406], [0.514136]]\n"
     ]
    }
   ],
   "source": [
    "Data_scaled = scaler.transform(test_data4)\n",
    "Data_scaled = Data_scaled.reshape(1,n_steps_in,no_of_features)\n",
    "predicted_value = model.predict(Data_scaled)\n",
    "print('Predicted value : {}\\nActual Value    : {}' .format(predicted_value,test_target4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted value : [[0.11162008 0.11081509]]\n",
      "Actual Value    : [[0.026409], [0.013998]]\n"
     ]
    }
   ],
   "source": [
    "Data_scaled = scaler.transform(test_data5)\n",
    "Data_scaled = Data_scaled.reshape(1,n_steps_in,no_of_features)\n",
    "predicted_value = model.predict(Data_scaled)\n",
    "print('Predicted value : {}\\nActual Value    : {}' .format(predicted_value,test_target5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted value : [[0.11143426 0.11305314]]\n",
      "Actual Value    : [[0.0294], [0.057255]]\n"
     ]
    }
   ],
   "source": [
    "Data_scaled = scaler.transform(test_data6)\n",
    "Data_scaled = Data_scaled.reshape(1,n_steps_in,no_of_features)\n",
    "predicted_value = model.predict(Data_scaled)\n",
    "print('Predicted value : {}\\nActual Value    : {}' .format(predicted_value,test_target6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
