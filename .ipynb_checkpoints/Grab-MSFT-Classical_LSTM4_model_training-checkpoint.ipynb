{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grab-Microsoft Challenge \n",
    "## Traffic Management\n",
    "\n",
    "- geohash6: geohash is a public domain geocoding system which encodes a geographic location into a short string of letters and digits with arbitrary precision. You are free to use any geohash library to encode/decode the geohashes into latitude and longitude or vice versa.(Examples:https://github.com/hkwi/python-geohash)\n",
    "- day: the value indicates the sequential order and not a particular day of the month\n",
    "- timestamp: start time of 15-minute intervals in the following format: <hour>:<minute>, where hour ranges from 0 to 23 and minute is either one of (0, 15, 30, 45)\n",
    "- demand: aggregated demand normalised to be in the range [0,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is train LSTM model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import python library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plot matplotlib graph\n",
    "%matplotlib inline\n",
    "\n",
    "#Import models from scikit learn module:\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Flatten, LSTM, BatchNormalization\n",
    "from tensorflow.keras import regularizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import h5py\n",
    "import sklearn.metrics as metrics\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,CSVLogger\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.utils import plot_model \n",
    "\n",
    "import pickle\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "modelname   = 'LSTM4'\n",
    "batch_size = 48\n",
    "no_of_epoch = 5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createModel(): \n",
    "    inputs  = Input(shape=(X_train1.shape[1],X_train1.shape[2]))\n",
    "    y = LSTM(units=32, return_sequences=True, dropout=0.5, recurrent_dropout=0.2)(inputs)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = LSTM(64, return_sequences=True, dropout=0.5, recurrent_dropout=0.2)(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = LSTM(64, return_sequences=True, dropout=0.5, recurrent_dropout=0.3)(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = LSTM(48, return_sequences=True, dropout=0.5, recurrent_dropout=0.4)(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = LSTM(32, return_sequences=True, dropout=0.5,recurrent_dropout=0.5)(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = LSTM(16, dropout=0.5,recurrent_dropout=0.5)(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Dense(1, activation='sigmoid')(y)\n",
    "  \n",
    "    model = Model(inputs=inputs,outputs=y)\n",
    "    model.compile(loss='mse',optimizer='adam', metrics=['mse', 'mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading from Preprocessed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xls  = pd.ExcelFile('data/Dataset_feature1.xlsx')\n",
    "data = pd.read_excel(xls, 'TrafficMgmt')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_var = ['day', 'hour', 'min', 'dow', 'lat', 'long','geo_labelencoded']\n",
    "outcome_var   = 'demand'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare training & test data\n",
    "- Since this is a time series dataset, we can try using LSTM \n",
    "- and create a time series of say 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_X = data.drop(outcome_var,axis=1)\n",
    "y      = data.drop(predictor_var,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "for i in range(20):\n",
    "    X.append(data_X.shift(-1-i).fillna(-1).values)\n",
    "X = np.array(X)\n",
    "\n",
    "X = X.reshape(X.shape[1],X.shape[0],X.shape[2])\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train-test-val dataset split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42,shuffle=True)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train1 = np.asarray(X_train)\n",
    "y_train1 = np.asarray(y_train)\n",
    "X_test1  = np.asarray(X_test)\n",
    "y_test1  = np.asarray(y_test)\n",
    "X_val1  = np.asarray(X_val)\n",
    "y_val1  = np.asarray(y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><center>Create Model and test</center><h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>LSTM<h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = createModel()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse',optimizer='adam', metrics=['mse', 'mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create checkpoints to save model during training and save training data into csv\n",
    "# ‘monitor’ can be ‘val_acc’ or ‘val_loss’\n",
    "# When set to ‘val_acc’, ‘mode’ must be ‘max’; when set to ‘val_loss’, ‘mode’ must be ‘min’\n",
    "\n",
    "filepath       = modelname + \".hdf5\"\n",
    "checkpoint     = ModelCheckpoint(filepath, monitor='val_loss',verbose=0,save_best_only=True,mode='min') \n",
    "csv_logger     = CSVLogger(modelname + '.csv')\n",
    "callbacks_list = [checkpoint,csv_logger]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The line for training\n",
    "model.fit(X_train1, \n",
    "          y_train1, \n",
    "          validation_data=(X_val1, y_val1), \n",
    "            epochs=no_of_epoch, \n",
    "            batch_size=batch_size,\n",
    "            shuffle=True,\n",
    "            callbacks=callbacks_list) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### validation dataset test result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts = model.predict(X_val1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mean_squared_error(y_val1,predicts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test dataset test result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_value = model.predict(X_test1)\n",
    "print(mean_squared_error(y_test1,predicted_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records     = pd.read_csv(modelname +'.csv')\n",
    "plt.figure()\n",
    "plt.subplot(211)\n",
    "plt.plot(records['val_loss'])\n",
    "plt.plot(records['val_mse'])\n",
    "plt.yticks([0.00,0.01,0.05,0.1])\n",
    "plt.title('MSE',fontsize=12)\n",
    "\n",
    "ax          = plt.gca()\n",
    "ax.set_xticklabels([])\n",
    "\n",
    "\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.plot(records['val_loss'])\n",
    "plt.plot(records['val_mae'])\n",
    "plt.yticks([0.00,0.01,0.05,0.1])\n",
    "plt.title('MAE',fontsize=12)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your own trained model\n",
    "model = load_model(MODEL_PATH, compile = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
