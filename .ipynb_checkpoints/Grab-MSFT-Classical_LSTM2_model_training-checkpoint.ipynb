{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grab-Microsoft Challenge \n",
    "## Traffic Management\n",
    "\n",
    "- geohash6: geohash is a public domain geocoding system which encodes a geographic location into a short string of letters and digits with arbitrary precision. You are free to use any geohash library to encode/decode the geohashes into latitude and longitude or vice versa.(Examples:https://github.com/hkwi/python-geohash)\n",
    "- day: the value indicates the sequential order and not a particular day of the month\n",
    "- timestamp: start time of 15-minute intervals in the following format: <hour>:<minute>, where hour ranges from 0 to 23 and minute is either one of (0, 15, 30, 45)\n",
    "- demand: aggregated demand normalised to be in the range [0,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is train LSTM model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import python library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plot matplotlib graph\n",
    "%matplotlib inline\n",
    "\n",
    "#Import models from scikit learn module:\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Flatten, LSTM, BatchNormalization\n",
    "from tensorflow.keras import regularizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import h5py\n",
    "import sklearn.metrics as metrics\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,CSVLogger\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.utils import plot_model \n",
    "\n",
    "import pickle\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "modelname   = 'LSTM2'\n",
    "batch_size  = 32768\n",
    "no_of_epoch = 10\n",
    "optmz       = 'adam'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createModel(): \n",
    "    inputs  = Input(shape=(X_train1.shape[1],X_train1.shape[2]))\n",
    "    y = LSTM(units=32, return_sequences=True, dropout=0.2, recurrent_dropout=0.2)(inputs)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = LSTM(128, return_sequences=True, dropout=0.3, recurrent_dropout=0.2)(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = LSTM(128, return_sequences=True, dropout=0.3, recurrent_dropout=0.3)(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = LSTM(64, return_sequences=True, dropout=0.4, recurrent_dropout=0.4)(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = LSTM(48, return_sequences=True, dropout=0.5,recurrent_dropout=0.5)(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = LSTM(32, return_sequences=True, dropout=0.5,recurrent_dropout=0.5)(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Dense(1, activation='sigmoid')(y)\n",
    "  \n",
    "    model = Model(inputs=inputs,outputs=y)\n",
    "    model.compile(loss='mse',optimizer='adam', metrics=['mse', 'mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading from Preprocessed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>demand</th>\n",
       "      <th>hour</th>\n",
       "      <th>min</th>\n",
       "      <th>dow</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>geo_labelencoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.283333</td>\n",
       "      <td>0.020072</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.161462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.024721</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.288889</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.071592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.102821</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.644444</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.795887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.516667</td>\n",
       "      <td>0.088755</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.530845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.074468</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.288889</td>\n",
       "      <td>0.342857</td>\n",
       "      <td>0.348819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048570</th>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.024022</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.911111</td>\n",
       "      <td>0.771429</td>\n",
       "      <td>0.956588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048571</th>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.005703</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.297030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048572</th>\n",
       "      <td>0.683333</td>\n",
       "      <td>0.067131</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.178218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048573</th>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.151323</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.711111</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.648134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048574</th>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.026007</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.688889</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.821021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1048575 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              day    demand      hour       min       dow       lat      long  \\\n",
       "0        0.283333  0.020072  0.869565  0.000000  0.666667  0.533333  0.171429   \n",
       "1        0.150000  0.024721  0.608696  0.666667  0.500000  0.288889  0.200000   \n",
       "2        0.133333  0.102821  0.260870  0.333333  0.333333  0.644444  0.828571   \n",
       "3        0.516667  0.088755  0.217391  0.000000  0.666667  0.533333  0.428571   \n",
       "4        0.233333  0.074468  0.173913  0.000000  0.166667  0.288889  0.342857   \n",
       "...           ...       ...       ...       ...       ...       ...       ...   \n",
       "1048570  0.083333  0.024022  0.347826  0.666667  1.000000  0.911111  0.771429   \n",
       "1048571  0.366667  0.005703  0.652174  0.666667  0.333333  0.111111  0.400000   \n",
       "1048572  0.683333  0.067131  0.652174  1.000000  0.000000  0.533333  0.200000   \n",
       "1048573  0.016667  0.151323  0.260870  0.666667  0.333333  0.711111  0.600000   \n",
       "1048574  0.066667  0.026007  0.434783  1.000000  0.833333  0.688889  0.800000   \n",
       "\n",
       "         geo_labelencoded  \n",
       "0                0.161462  \n",
       "1                0.071592  \n",
       "2                0.795887  \n",
       "3                0.530845  \n",
       "4                0.348819  \n",
       "...                   ...  \n",
       "1048570          0.956588  \n",
       "1048571          0.297030  \n",
       "1048572          0.178218  \n",
       "1048573          0.648134  \n",
       "1048574          0.821021  \n",
       "\n",
       "[1048575 rows x 8 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xls  = pd.ExcelFile('data/Dataset_feature1.xlsx')\n",
    "data = pd.read_excel(xls, 'TrafficMgmt')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_var = ['day', 'hour', 'min', 'dow', 'lat', 'long','geo_labelencoded']\n",
    "outcome_var   = 'demand'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare training & test data\n",
    "- Since this is a time series dataset, we can try using LSTM \n",
    "- and create a time series of say 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_X = data.drop(outcome_var,axis=1)\n",
    "y      = data.drop(predictor_var,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1048575, 20, 7)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = []\n",
    "for i in range(20):\n",
    "    X.append(data_X.shift(-1-i).fillna(-1).values)\n",
    "X = np.array(X)\n",
    "\n",
    "X = X.reshape(X.shape[1],X.shape[0],X.shape[2])\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.15      ,  0.60869565,  0.66666667, ...,  0.28888889,\n",
       "          0.2       ,  0.07159177],\n",
       "        [ 0.13333333,  0.26086957,  0.33333333, ...,  0.64444444,\n",
       "          0.82857143,  0.79588728],\n",
       "        [ 0.51666667,  0.2173913 ,  0.        , ...,  0.53333333,\n",
       "          0.42857143,  0.53084539],\n",
       "        ...,\n",
       "        [ 0.78333333,  0.47826087,  0.66666667, ...,  0.37777778,\n",
       "          0.05714286,  0.03808073],\n",
       "        [ 0.26666667,  1.        ,  1.        , ...,  0.77777778,\n",
       "          0.62857143,  0.65955826],\n",
       "        [ 0.91666667,  0.43478261,  0.        , ...,  0.28888889,\n",
       "          0.48571429,  0.36785986]],\n",
       "\n",
       "       [[ 0.85      ,  0.47826087,  0.        , ...,  1.        ,\n",
       "          0.82857143,  0.97258187],\n",
       "        [ 0.93333333,  0.7826087 ,  0.66666667, ...,  0.77777778,\n",
       "          0.62857143,  0.65955826],\n",
       "        [ 0.33333333,  0.26086957,  0.        , ...,  0.77777778,\n",
       "          0.54285714,  0.65346535],\n",
       "        ...,\n",
       "        [ 0.8       ,  0.2173913 ,  0.33333333, ...,  0.24444444,\n",
       "          0.57142857,  0.42650419],\n",
       "        [ 0.58333333,  0.2173913 ,  0.        , ...,  0.73333333,\n",
       "          0.37142857,  0.56054836],\n",
       "        [ 0.4       ,  0.13043478,  0.33333333, ...,  0.62222222,\n",
       "          0.11428571,  0.16755522]],\n",
       "\n",
       "       [[ 0.86666667,  0.26086957,  0.33333333, ...,  0.97777778,\n",
       "          0.31428571,  0.88880427],\n",
       "        [ 0.83333333,  0.        ,  0.33333333, ...,  0.37777778,\n",
       "          0.48571429,  0.39908606],\n",
       "        [ 0.63333333,  0.69565217,  0.66666667, ...,  0.48888889,\n",
       "          0.85714286,  0.74562072],\n",
       "        ...,\n",
       "        [ 0.83333333,  0.47826087,  0.33333333, ...,  0.71111111,\n",
       "          0.08571429,  0.20258949],\n",
       "        [ 0.18333333,  0.95652174,  1.        , ...,  1.        ,\n",
       "          0.94285714,  0.99390708],\n",
       "        [ 0.06666667,  0.86956522,  0.66666667, ...,  0.51111111,\n",
       "          0.94285714,  0.80426504]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 0.65      ,  0.43478261,  1.        , ...,  0.33333333,\n",
       "          0.02857143,  0.03351104],\n",
       "        [ 0.13333333,  1.        ,  1.        , ...,  0.6       ,\n",
       "          0.22857143,  0.19116527],\n",
       "        [ 0.83333333,  0.47826087,  0.33333333, ...,  0.4       ,\n",
       "          0.02857143,  0.03731912],\n",
       "        ...,\n",
       "        [ 0.65      ,  0.17391304,  0.66666667, ...,  0.82222222,\n",
       "          0.17142857,  0.22239147],\n",
       "        [ 0.65      ,  0.43478261,  0.        , ...,  0.08888889,\n",
       "          0.4       ,  0.29474486],\n",
       "        [ 0.6       ,  0.04347826,  1.        , ...,  0.64444444,\n",
       "          0.45714286,  0.5468393 ]],\n",
       "\n",
       "       [[ 0.43333333,  1.        ,  0.33333333, ...,  0.66666667,\n",
       "          0.91428571,  0.81340442],\n",
       "        [ 0.66666667,  0.        ,  1.        , ...,  0.77777778,\n",
       "          0.54285714,  0.65346535],\n",
       "        [ 0.68333333,  0.52173913,  0.66666667, ...,  0.35555556,\n",
       "          0.65714286,  0.48667174],\n",
       "        ...,\n",
       "        [ 0.68333333,  0.65217391,  1.        , ...,  0.53333333,\n",
       "          0.2       ,  0.17821782],\n",
       "        [ 0.01666667,  0.26086957,  0.66666667, ...,  0.71111111,\n",
       "          0.6       ,  0.64813404],\n",
       "        [ 0.06666667,  0.43478261,  1.        , ...,  0.68888889,\n",
       "          0.8       ,  0.82102056]],\n",
       "\n",
       "       [[-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "         -1.        , -1.        ],\n",
       "        [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "         -1.        , -1.        ],\n",
       "        [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "         -1.        , -1.        ],\n",
       "        ...,\n",
       "        [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "         -1.        , -1.        ],\n",
       "        [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "         -1.        , -1.        ],\n",
       "        [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "         -1.        , -1.        ]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1048575, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1048575, 20, 7)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train-test-val dataset split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42,shuffle=True)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train1 = np.asarray(X_train)\n",
    "y_train1 = np.asarray(y_train)\n",
    "X_test1  = np.asarray(X_test)\n",
    "y_test1  = np.asarray(y_test)\n",
    "X_val1  = np.asarray(X_val)\n",
    "y_val1  = np.asarray(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(671088, 20, 7)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(671088, 1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(167772, 20, 7)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(167772, 1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><center>Create Model and test</center><h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>LSTM<h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 20, 7)]           0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 20, 32)            5120      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 20, 32)            128       \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 20, 128)           82432     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 20, 128)           512       \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 20, 128)           131584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 20, 128)           512       \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 20, 64)            49408     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 20, 64)            256       \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 20, 48)            21696     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 20, 48)            192       \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 20, 32)            10368     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 20, 32)            128       \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 20, 1)             33        \n",
      "=================================================================\n",
      "Total params: 302,369\n",
      "Trainable params: 301,505\n",
      "Non-trainable params: 864\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = createModel()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse',optimizer='adam', metrics=['mse', 'mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create checkpoints to save model during training and save training data into csv\n",
    "# â€˜monitorâ€™ can be â€˜val_accâ€™ or â€˜val_lossâ€™\n",
    "# When set to â€˜val_accâ€™, â€˜modeâ€™ must be â€˜maxâ€™; when set to â€˜val_lossâ€™, â€˜modeâ€™ must be â€˜minâ€™\n",
    "\n",
    "filepath       = modelname + \".hdf5\"\n",
    "checkpoint     = ModelCheckpoint(filepath, monitor='val_loss',verbose=0,save_best_only=True,mode='min') \n",
    "csv_logger     = CSVLogger(modelname + '.csv')\n",
    "callbacks_list = [checkpoint,csv_logger]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "A target array with shape (671088, 1) was passed for an output of shape (None, 20, 1) while using as loss `mean_squared_error`. This loss expects targets to have the same shape as the output.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-733696ebbb9c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m                     \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m                     callbacks=callbacks_list) \n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\deep\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\deep\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    233\u001b[0m           \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m           \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 235\u001b[1;33m           use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    236\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_data_adapter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\deep\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36m_process_training_inputs\u001b[1;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, steps_per_epoch, validation_split, validation_data, validation_steps, shuffle, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    591\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 593\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    594\u001b[0m     \u001b[0mval_adapter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\deep\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[1;34m(model, mode, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    644\u001b[0m     \u001b[0mstandardize_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    645\u001b[0m     x, y, sample_weights = standardize(\n\u001b[1;32m--> 646\u001b[1;33m         x, y, sample_weight=sample_weights)\n\u001b[0m\u001b[0;32m    647\u001b[0m   \u001b[1;32melif\u001b[0m \u001b[0madapter_cls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mdata_adapter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mListsOfScalarsDataAdapter\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    648\u001b[0m     \u001b[0mstandardize_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstandardize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\deep\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[0;32m   2381\u001b[0m         \u001b[0mis_dataset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_dataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2382\u001b[0m         \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2383\u001b[1;33m         batch_size=batch_size)\n\u001b[0m\u001b[0;32m   2384\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2385\u001b[0m   def _standardize_tensors(self, x, y, sample_weight, run_eagerly, dict_inputs,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\deep\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_tensors\u001b[1;34m(self, x, y, sample_weight, run_eagerly, dict_inputs, is_dataset, class_weight, batch_size)\u001b[0m\n\u001b[0;32m   2487\u001b[0m           \u001b[1;31m# Additional checks to avoid users mistakenly using improper loss fns.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2488\u001b[0m           training_utils.check_loss_and_target_compatibility(\n\u001b[1;32m-> 2489\u001b[1;33m               y, self._feed_loss_fns, feed_output_shapes)\n\u001b[0m\u001b[0;32m   2490\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2491\u001b[0m       sample_weights, _, _ = training_utils.handle_partial_sample_weights(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\deep\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mcheck_loss_and_target_compatibility\u001b[1;34m(targets, loss_fns, output_shapes)\u001b[0m\n\u001b[0;32m    808\u001b[0m           raise ValueError('A target array with shape ' + str(y.shape) +\n\u001b[0;32m    809\u001b[0m                            \u001b[1;34m' was passed for an output of shape '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 810\u001b[1;33m                            \u001b[1;34m' while using as loss `'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mloss_name\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'`. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    811\u001b[0m                            \u001b[1;34m'This loss expects targets to have the same shape '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    812\u001b[0m                            'as the output.')\n",
      "\u001b[1;31mValueError\u001b[0m: A target array with shape (671088, 1) was passed for an output of shape (None, 20, 1) while using as loss `mean_squared_error`. This loss expects targets to have the same shape as the output."
     ]
    }
   ],
   "source": [
    "# The line for training\n",
    "history = model.fit(X_train1, \n",
    "                    y_train1, \n",
    "                    validation_data=(X_val1, y_val1), \n",
    "                    epochs=no_of_epoch, \n",
    "                    batch_size=batch_size,\n",
    "                    shuffle=True,\n",
    "                    callbacks=callbacks_list) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### validation dataset test result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts = model.predict(X_val1)\n",
    "print(mean_squared_error(y_val1,predicts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test dataset test result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_value = model.predict(X_test1)\n",
    "print(mean_squared_error(y_test1,predicted_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records     = pd.read_csv(modelname +'.csv')\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.subplot(211)\n",
    "plt.plot(records['val_mse'],label=\"mse_loss\")\n",
    "plt.plot(records['val_loss'],label=\"val_loss\")\n",
    "plt.plot(records['loss'],label=\"loss\")\n",
    "plt.title('MSE',fontsize=12)\n",
    "plt.legend(loc=\"upper left\",fontsize=15)\n",
    "\n",
    "ax          = plt.gca()\n",
    "ax.set_xticklabels([])\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.plot(records['val_mae'],label=\"val_mae\")\n",
    "plt.plot(records['val_loss'],label=\"val_loss\")\n",
    "plt.plot(records['loss'],label=\"loss\")\n",
    "plt.title('MAE',fontsize=12)\n",
    "plt.legend(loc=\"upper left\",fontsize=15)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "train_mse = model.evaluate(X_train1, y_train, verbose=0)\n",
    "test_mse = model.evaluate(X_test1, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot loss during training\n",
    "plt.title('Loss / Mean Squared Error')\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing using 1 row of inference data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data input sequence format :\n",
    "test_data1   = [[18,20, 0, 4, -5.353088, 90.653687]]\n",
    "test_data1   = pd.DataFrame(test_data1, columns = predictor_var)\n",
    "test_target1 = [0.020072]\n",
    "\n",
    "test_data2   = [[10,14,30, 3, -5.413513, 90.664673]]\n",
    "test_data2   = pd.DataFrame(test_data2, columns = predictor_var)\n",
    "test_target2 = [0.024721] \n",
    "\n",
    "test_data3   = [[ 9, 6,15, 2, -5.325623, 90.906372]]\n",
    "test_data3   = pd.DataFrame(test_data3, columns = predictor_var)\n",
    "test_target3 = [0.102821]\n",
    "\n",
    "test_data4   = [[32, 5, 0, 4, -5.353088, 90.752563]]\n",
    "test_data4   = pd.DataFrame(test_data4, columns = predictor_var)\n",
    "test_target4 = [0.088755]\n",
    "\n",
    "test_data5   = [[15, 4, 0, 1, -5.413513, 90.719604]]\n",
    "test_data5   = pd.DataFrame(test_data5, columns = predictor_var)\n",
    "test_target5 = [0.074468]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_filename = \"grab_msft_scaler.save\"\n",
    "scaler          = joblib.load(scaler_filename) \n",
    "Data_scaled = scaler.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_scaled = Data_scaled.reshape(1,1,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_scaled[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_shift = np.repeat(Data_scaled[:, :, np.newaxis], 20, axis=2).reshape(1,20,7)\n",
    "X_shift.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_value = model.predict(X_shift)\n",
    "print('Predicted value : {}\\nActual Value    : {}' .format(predicted_value[0][0],test_target[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mean_squared_error(test_target,predicted_value))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
